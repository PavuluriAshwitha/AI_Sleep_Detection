# -*- coding: utf-8 -*-
"""series&events_(1)_(1) (2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cCRqb46mBIQYqng_V6QXcNJ2wqwh0Jvf

# üí§ Sleep Event Detection from Accelerometer Data

## üìå Problem Statement
Build a model to detect **sleep onset** and **wakeup** events using wrist-worn accelerometer data collected over multiple days.

## üß† Objective
Use the given accelerometer features (`anglez`, `enmo`) to predict:
- When the user **falls asleep** (onset)
- When the user **wakes up** (wakeup)

## üìÇ Dataset
- `train_series.parquet`: Accelerometer time series (`series_id`, `step`, `timestamp`, `anglez`, `enmo`)
- `train_events.csv`: Ground truth sleep events (`onset` and `wakeup`)
- `test_series.parquet`: Similar time series without labels (for prediction)

## ‚úÖ Rules for Sleep Detection
- Sleep must last **‚â• 30 minutes**
- Can include short activity bursts **< 30 minutes**
- Only **one sleep window per night**
- No predictions if the device is **not worn**

## üéØ Goal
Accurately detect sleep events in the test data, avoiding false positives and respecting real-world sleep patterns.
"""

!pip install polars
!pip install pyarrow
!pip install dask
!pip install imblearn

import pandas as pd
import pyarrow as pa
import polars as pl
import pyarrow.parquet as pq
from google.colab import drive
import os
import pyarrow.parquet as pq
import dask.dataframe as dd
from warnings import filterwarnings
filterwarnings('ignore')
from imblearn.over_sampling import SMOTE

from google.colab import drive
drive.mount('/content/drive')

file=("/content/drive/MyDrive/Sleep_Data/train_series.parquet")# train_series
file1=("/content/drive/MyDrive/Sleep_Data/train_events.csv")# train_events
file2=("/content/drive/MyDrive/Sleep_Data/test_series.parquet")# test_series

data=dd.read_parquet(file)
df=data.copy()
data1=pd.read_csv(file1)
df1=data1.copy()
data2=dd.read_parquet(file2)
df2=data2.copy()

"""## üóÉÔ∏è Dataset: `train_series.parquet`

This dataset contains **time series sensor readings** collected from wearable devices worn by users during sleep studies.

### üîë Columns:

| Column Name | Data Type | Description |
|-------------|------------|-------------|
| `series_id` | `string`   | Unique identifier for each user's recording session. |
| `step`      | `int`      | Sequential time step (in 5-second intervals). |
| `timestamp` | `datetime` | Actual date and time of the sensor reading (with timezone). |
| `anglez`    | `float`    | Z-axis angle from accelerometer (post-processed). |
| `enmo`      | `float`    | Euclidean Norm Minus One (used to estimate physical activity or movement). |

### üìå Notes:

- Each `series_id` corresponds to a specific sleep recording session.
- Readings are collected every **5 seconds**.
- This data is typically used to classify sleep and wake states using motion patterns.

"""

df.compute()

"""### üìä Simple EDA"""

df.info(verbose=True)

# Display basic info
df.dtypes

# Display first few rows
df.head()

# Check for missing values
df.isnull().sum().compute()

# Summary statistics
df.describe().compute()

"""### üìä Simple EDA on `train_series.parquet`

1. **Number of Records**  
   - Total rows: ~46 million  
   - Number of unique `series_id`: 277

2. **Time Interval Check**  
   - Data recorded every **5 seconds**  
   - Each `series_id` represents a **continuous time series**

3. **Missing Values**  
   - No missing values in any column

4. **Value Ranges**  
   - `anglez`: ranges from around **-90 to +90**, representing tilt orientation  
   - `enmo`: mostly low values, indicating **minimal movement** during sleep

5. **ENMO Insights**  
   - Low `enmo` values suggest **sleep periods**  
   - High `enmo` spikes may indicate **awake movements**

"""

# Count unique series IDs
df['series_id'].nunique().compute()

"""### üßπ Preprocessing"""

# changing the datatype  series_id & timestamp (Train_paraquet)
df["series_id"] = df["series_id"].astype("category")
df['timestamp'] = dd.to_datetime(df['timestamp'],utc=True)

"""1. **Datetime Parsing**
   - Convert `timestamp` to `datetime`
"""

ddf = dd.read_parquet(file)
series_to_keep = ddf['series_id'].unique().compute().tolist()[:100]  # Select first 100
# Use 'ddf' instead of 'df' for filtering to ensure consistency
filtered_ddf = ddf[ddf['series_id'].isin(series_to_keep)]
filtered_ddf.to_parquet("subset_train_series.parquet", compression='snappy')

"""**The dataset contains 127,946,340 records, which small processors cannot handle efficiently. Given this limitation, we have selected 100 unique IDs out of the 277, reducing the data size to 46195920 million records, making it more manageable for the processors.**

"""

se=dd.read_parquet("subset_train_series.parquet")
series=se.copy()

series.head()

series.isnull().sum().compute()

anglez_min = series['anglez'].min().compute() # Smallest value in anglez
anglez_max = series['anglez'].max().compute()  # Largest value in anglez

enmo_min = series['enmo'].min().compute()   # Smallest value in enmo
enmo_max = series['enmo'].max().compute()  # Largest value in enmo

print(anglez_min)
print(anglez_max)
print(enmo_min)
print(enmo_max)

"""### üîç Sensor Features Description: `enmo` and `anglez`

#### 1. üìà enmo (Euclidean Norm Minus One)
- **Definition**: Measures movement intensity using accelerometer data.
- **Formula**: `enmo = sqrt(x¬≤ + y¬≤ + z¬≤) - 1`
- **Typical Range**:
  - **Min**: ~0.0
  - **Max**: ~2.5 (occasionally higher for very active movement)
  - **Mean**: ~0.04 (from EDA)
- **Interpretation**:
  - `enmo ‚âà 0`: Very little to no movement (e.g., during sleep).
  - `enmo > 0.1`: Mild movement.
  - `enmo > 0.2`: Indicates walking or physical activity.
  - **Spikes** in `enmo` can be used to detect wakefulness or restlessness.

#### 2. üìê anglez (Z-Axis Angle)
- **Definition**: Measures the angle of the accelerometer relative to the vertical (Z) axis.
- **Typical Range**:
  - **Min**: ~-180¬∞
  - **Max**: ~180¬∞
  - **Mean**: ~0.5¬∞
  - **Std Dev**: ~30¬∞
- **Interpretation**:
  - Indicates body orientation ‚Äî e.g., lying down vs sitting/standing.
  - Sudden **changes in anglez** may indicate posture shifts (like turning in bed).
  - Consistent values over long periods suggest inactivity or stable sleep position.

#### 3. üß† Usage in Sleep Detection
- **Sleep State (1)**: Low `enmo`, stable `anglez`.
- **Wake State (0)**: High `enmo`, fluctuating `anglez`.
- Can be combined to create robust features for classifying sleep/wake windows.


"""

series['series_id'].nunique().compute()

"""### üìä Exploratory Data Analysis ‚Äì `train_series.parquet`

#### 1. Dataset Overview
- **Total Rows**: ~46.2 million
- **Total Columns**: 5
- **Unique Series IDs**: 100
"""

import polars as pl
series = (pl.scan_parquet('subset_train_series.parquet')
                .with_columns(
                    (
                        (pl.col("timestamp").str.strptime(pl.Datetime, "%Y-%m-%dT%H:%M:%S%Z")),
                        (pl.col("timestamp").str.strptime(pl.Datetime, "%Y-%m-%dT%H:%M:%S%Z").dt.year().alias("year")),
                        (pl.col("timestamp").str.strptime(pl.Datetime, "%Y-%m-%dT%H:%M:%S%Z").dt.month().alias("month")),
                        (pl.col("timestamp").str.strptime(pl.Datetime, "%Y-%m-%dT%H:%M:%S%Z").dt.day().alias("day")),
                        (pl.col("timestamp").str.strptime(pl.Datetime, "%Y-%m-%dT%H:%M:%S%Z").dt.hour().alias("hour")),
                        (pl.col("timestamp").str.strptime(pl.Datetime, "%Y-%m-%dT%H:%M:%S%Z").dt.minute().alias("minute")),
                        (pl.col("timestamp").str.strptime(pl.Datetime, "%Y-%m-%dT%H:%M:%S%Z").dt.second().alias("second")),
                    )
                )
                .collect()
                .to_pandas()
               )

series.head()

series =series.drop(columns=['__null_dask_index__'], errors='ignore')

series.head()

"""## Exploratory Data Analysis"""

import matplotlib.pyplot as plt
import seaborn as sns

# Create a figure with two subplots
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Histogram with custom color
sns.histplot(series['enmo'], kde=True, ax=axes[0], color='royalblue')
axes[0].set_title('Distribution of ENMO')
axes[0].set_xlabel('ENMO')
axes[0].set_ylabel('Frequency')

# Box plot with custom color
sns.boxplot(y=series['enmo'], ax=axes[1], color='tomato')
axes[1].set_title('Box Plot of ENMO')
axes[1].set_ylabel('ENMO')

plt.tight_layout()
plt.show()

"""# Detailed Insights from ENMO Histogram & Box Plot  

## üìå Histogram Insights (Movement Distribution):  
- The **highly right-skewed** distribution suggests that **most ENMO values are close to zero**, meaning the subject was **inactive or in a resting state** for a significant period (e.g., sleeping or lying still).  
- The **long tail** indicates **sporadic bursts of activity**, likely due to **physical movements** such as **turning in bed, waking up briefly, or other short-duration activities**.  
- The **sharp peak near zero** suggests **long stationary periods**, which aligns with expected sleep patterns where movement is minimal.  

## üìå Box Plot Insights (Variability & Outliers):  
- **Many outliers** (dots above the whiskers) indicate **frequent spikes in movement**. These could correspond to:  
  - **Restless movements during sleep** (e.g., tossing and turning).  
  - **Brief wake-up periods** where the subject moved significantly.  
  - **Sensor anomalies** or environmental factors affecting the data.  
- The **median (central line in the box) is very close to zero**, meaning that for **half of the recorded time, the subject had almost no movement**.  
- The **whiskers (upper & lower range)** show that **most normal movement values are very small**, reinforcing that the subject was stationary most of the time.  

"""

import matplotlib.pyplot as plt
import seaborn as sns

# Create subplots
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Histogram + KDE Plot
sns.histplot(series['anglez'], bins=100, kde=True, color='salmon', ax=axes[0])
axes[0].set_title('Distribution of anglez')
axes[0].set_xlabel('anglez')
axes[0].set_ylabel('Frequency')
axes[0].grid(True)

# Boxplot
sns.boxplot(x=series['anglez'], color='lightcoral', ax=axes[1])
axes[1].set_title('Boxplot of anglez')
axes[1].set_xlabel('anglez')
axes[1].grid(True)

# Adjust layout
plt.tight_layout()
plt.show()

"""## üìà Insights from `anglez` Distribution and Boxplot

---

### üìä Distribution of `anglez`

- **Distribution Shape**: The distribution of `anglez` is **left-skewed**, with a longer tail on the negative side.
- **Concentration Zone**: Most values lie around **-20 to 0**, indicating common wrist/body angles in that range ‚Äî potentially during rest or sleep.
- **Range**: The `anglez` values span approximately from **-90 to +90 degrees**, covering the entire spectrum of orientation.
- **Multimodality**: Minor bumps suggest **recurring motion patterns**, possibly related to sleep cycles or habitual movements.

---

### üì¶ Boxplot of `anglez`

- **IQR & Median**:
  - The **median** is positioned slightly left of center.
  - The **interquartile range (IQR)** mostly spans **-30 to +10**.
- **Outliers**:
  - Clear presence of **outliers**, especially in the **positive range** (> +75¬∞).
  - These outliers could represent abrupt changes in wrist position or motion noise.
- **Compactness**: The central range is dense, suggesting a consistent wrist orientation during most of the recorded time.

---

### üß† Key Takeaways

- The majority of wrist angle readings are within **-30¬∞ to +10¬∞**, aligning with periods of minimal activity.
- Presence of outliers and skewness highlights **occasional sudden movements**.
- `anglez` could be an important feature for **distinguishing between sleep and wake periods**, especially when used with activity measures like `enmo`.

"""

# Univariate analysis for 'step'
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Histogram of 'step'
sns.histplot(series['step'], bins=50, ax=axes[0], kde=True, color='skyblue')
axes[0].set_title('Distribution of Step')
axes[0].set_xlabel('Step')
axes[0].set_ylabel('Frequency')
axes[0].grid(True)


# Boxplot of 'step'
sns.boxplot(x=series['step'], ax=axes[1], color='lightcoral')
axes[1].set_title('Boxplot of Step')
axes[1].set_xlabel('Step')
axes[1].grid(True)

plt.tight_layout()
plt.show()

"""## üìä Insights from Step Feature Distribution and Boxplot

### 1. Distribution Plot (Left Panel)
- The **distribution of the `step` variable is right-skewed**.
- Most values are concentrated between **0 and 400,000**, with a sharp decline after that.
- There are very few extremely high values, indicating **possible outliers**.
- The majority of data points fall in the **lower step count range**, suggesting users are mostly inactive or only slightly active.

### 2. Boxplot (Right Panel)
- The boxplot clearly shows the **presence of outliers** far to the right.
- The **interquartile range (IQR)** is relatively narrow compared to the spread of the outliers.
- The **median step value** lies closer to the lower quartile, reaffirming the

"""

# Define a 1x2 subplot layout
fig, axes = plt.subplots(1, 2, figsize=(16, 4))

# Day plot
sns.countplot(x='day', data=series, ax=axes[0], palette='pastel')
axes[0].set_title('Distribution of Day')
axes[0].grid(True)

# Hour plot
sns.countplot(x='hour', data=series, ax=axes[1], palette='coolwarm')
axes[1].set_title('Distribution of Hour')
axes[1].grid(True)

# Adjust layout and show both plots together
plt.tight_layout()
plt.show()

"""## üìà Insights from Distribution of Day and Hour

### üìÖ Distribution of Day (Left Plot)
- The data is **fairly uniformly distributed** across all days of the month.
- Slight dips are seen on days like **9, 10, 21, and 31**, suggesting **fewer records** on these days‚Äîpossibly due to missing data or month-end variations.
- No single day dominates, which is good for **balanced time-based analysis**.

### ‚è∞ Distribution of Hour (Right Plot)
- The data is **evenly distributed across all 24 hours**, showing **no major gaps or peaks**.
- Slight upward trend in later hours (e.g., 18 to 23) possibly indicates **increased activity or logging** during evening hours.
- This consistent distribution supports **hourly time series modeling** without concern for data imbalance.

---

### üí° Recommendation
- No significant preprocessing needed for `day` or `hour` features in terms of balancing.
- These features can be safely used for **temporal analysis** or **feature engineering** (e.g., peak vs off-peak hours).

"""

fig, axes = plt.subplots(1, 2, figsize=(14, 4))
# Minute plot
sns.histplot(series['minute'], bins=60, ax=axes[0], kde=False, color='skyblue')
axes[0].set_title('Distribution of Minute')
axes[0].grid(True)

# Second plot
sns.histplot(series['second'], bins=60, ax=axes[1], kde=False, color='lightgreen')
axes[1].set_title('Distribution of Second')
axes[1].grid(True)

plt.tight_layout()
plt.show()

"""## üïí Insights from Distribution of Minute and Second

### üïê Distribution of Minute (Left Plot)
- The data is **evenly distributed across all 60 minutes**.
- Each minute has roughly **750,000‚Äì800,000 records**, suggesting that there is **no time-based sampling bias** within each hour.
- This uniformity is ideal for **fine-grained temporal analysis** (e.g., event frequency per minute).

### ‚è±Ô∏è Distribution of Second (Right Plot)
- The data appears to be **sampled at fixed intervals of 6 seconds** (i.e., seconds: 0, 6, 12, ..., 54).
- This consistent spacing implies that data collection is **not continuous per second**, but likely occurs every 6 seconds‚Äîperhaps due to **sensor constraints or storage optimization**.
- All sampled seconds have nearly identical counts (~3.8 million), confirming a **systematic sampling mechanism**.

## bivariate analysis
"""

# Bivariate analysis: Box plot of 'enmo' for different hours
plt.figure(figsize=(12, 6))
sns.boxplot(x='hour', y='enmo', data=series)
plt.title('Bivariate Analysis: ENMO Distribution by Hour')
plt.xlabel('Hour')
plt.ylabel('ENMO')
plt.xticks(rotation=45)  # Rotate x-axis labels for better readability if needed
plt.show()

"""## üìä Bivariate Analysis: ENMO Distribution by Hour

### üìå Key Observations:
- **Low ENMO activity** is observed during the **early morning hours (0‚Äì5 AM)**, which likely corresponds to **sleep time** for most individuals.
- **ENMO increases significantly** from around **6 AM**, with higher values maintained throughout the **daytime hours (8 AM‚Äì7 PM)**.
- The **peak ENMO activity** appears to occur around **midday to evening hours**, indicating periods of **increased physical movement**.
- A **gradual decline** in ENMO values is observed after **8 PM**, again suggesting **reduced activity** or **winding down for sleep**.
- There are **outliers** in all hours, but especially from 7 AM onward, reflecting **short bursts of intense activity**.

### üí° Interpretation:
- This pattern aligns with a typical human **circadian rhythm** ‚Äî low movement during sleep and high during wakefulness.
- ENMO could be a strong indicator feature for **sleep state classification** or **daily activity modeling**.

### ‚úÖ Actionable Insight:
- You can use **hourly ENMO trends** as an input for:
  - Sleep/wake detection models
  - Activity-level clustering
  - Chronotype identification (e.g., morning vs evening active individuals)

"""

plt.figure(figsize=(12, 4))
sns.boxplot(data=series, x="hour", y="anglez", palette="Blues")
plt.title("Hour vs Anglez")
plt.xlabel("Hour of Day")
plt.ylabel("Anglez")
plt.grid(True)
plt.tight_layout()
plt.show()

"""### üìä Bivariate Analysis: ENMO Distribution by Hour ‚Äì Key Observations

1. **Low ENMO values during early hours (0‚Äì5 AM)**  
   - Indicates low physical activity, likely corresponding to sleep.

2. **ENMO values rise from 6 AM onwards**  
   - Reflects increased movement as people wake up and begin daily routines.

3. **Highest ENMO levels between 8 AM and 7 PM**  
   - Corresponds to peak activity during the day.

4. **ENMO declines after 8 PM**  
   - Suggests reduced activity as people prepare for rest.

5. **Outliers present in all hours, especially during the day**  
   - Indicates short bursts of intense movement or variability in daily activity.

"""

plt.figure(figsize=(16, 4))
sns.boxplot(data=series, x="minute", y="enmo", palette="coolwarm")
plt.title("Minute vs ENMO")
plt.xlabel("Minute")
plt.ylabel("ENMO")
plt.grid(True)
plt.tight_layout()
plt.show()

"""### ‚è±Ô∏è Bivariate Analysis: ENMO Distribution by Minute ‚Äì Key Observations

1. **Relatively uniform ENMO distribution across all minutes (0‚Äì59)**  
   - No single minute stands out significantly in terms of activity level.

2. **Consistent range of ENMO values**  
   - Most values are centered around 3 to 5, with outliers above 6 across all minutes.

3. **Outliers observed in almost every minute**  
   - Indicates occasional bursts of higher activity but not tied to specific minute marks.

4. **Slightly denser clustering between minutes 0‚Äì10 and 45‚Äì50**  
   - Could reflect common routine behaviors, though not drastically different from other minutes.

## Multi variate Analysis
"""

plt.figure(figsize=(8, 6))

# Select relevant numeric columns
cols = ['step', 'anglez', 'enmo', 'hour', 'minute']

# Calculate the correlation matrix
corr_matrix = series[cols].corr()

# Plot the heatmap using the correlation matrix
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap="coolwarm", square=True, linewidths=0.5)
plt.title("Correlation Heatmap")
plt.tight_layout()
plt.show()

"""### üî• Correlation Heatmap ‚Äì Key Takeaways

1. **Weak correlations across features**
   - Most variables show very low correlation values (close to 0), suggesting weak linear relationships.

2. **ENMO and Hour (0.13)**  
   - Slight positive correlation, indicating that ENMO may increase marginally at certain hours.

3. **Negligible correlation between:**
   - `step` & `enmo` (-0.01)
   - `step` & `hour` (-0.01)
   - `step` & `minute` (0.00)
   - `anglez` & others (all near 0)

4. **Self-correlations are perfect (1.00)**  
   - As expected, each variable has a perfect correlation with itself.

> üí° Overall, no strong linear relationships observed between features, indicating the need for non-linear models or additional feature engineering for predictive tasks.

## Feature Engineering
"""

# # Define sleep/wake threshold based on ENMO
threshold = 0.03  # Experimentally chosen threshold for sleep detection
series['sleep_state'] = (series['enmo'] < threshold).astype(int)



# series.head()

series['rolling_mean_enmo'] = series['enmo'].rolling(window=60, min_periods=1).mean()

# If the rolling mean is consistently low, mark as sleep
series['sleep_state'] = (series['rolling_mean_enmo'] < 0.03).astype(int)

# # Calculate rolling mean of anglez (window of 60 seconds)
# series['rolling_mean_anglez'] = series['anglez'].rolling(window=60, min_periods=1).mean()

# # If the rolling mean is consistently low, mark as sleep
# series['sleep_state'] = (series['rolling_mean_anglez'].abs() < 5).astype(int)

series = series.drop(columns=['rolling_mean_anglez'], errors='ignore')

series.head()

series['sleep_state'].value_counts()

!pip install optuna
! pip install xgboost

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import StandardScaler

# ==== Step 1: Preprocessing ====

# Select features (X) and target (y)
X = series[['step', 'anglez', 'enmo']]  # Add more features if needed
y = series['sleep_state']

# Assume you already have X_test and y_test defined elsewhere
# So we directly apply SMOTE on full X and y

# Apply SMOTE to balance the training set
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# Standardize the features
scaler = StandardScaler()
X_resampled_scaled = scaler.fit_transform(X_resampled)
# X_test_scaled = scaler.transform(X_test)  # Assuming X_test is already defined

# Optional: check class distribution
print("Before SMOTE:\n", y.value_counts())
print("After SMOTE:\n", pd.Series(y_resampled).value_counts())
print("X shape:", X_resampled_scaled.shape)
print("y shape:", y_resampled.shape)

# print(X_train_resampled.shape)
# print(y_train_resampled.shape)

from sklearn.ensemble import RandomForestClassifier

# ==== Step 2: Model Training (No Testing) ====

# Initialize Random Forest Classifier
rf_model = RandomForestClassifier(
    n_estimators=100,            # Number of trees
    min_samples_split=10,        # Minimum samples required to split a node
    min_samples_leaf=5,          # Minimum samples required in a leaf
    random_state=42,
    n_jobs=-1
)

# Train the model on SMOTE-resampled and scaled data
rf_model.fit(X_resampled_scaled, y_resampled)

# import joblib

# # Save the model to a file
# joblib.dump(rf_model, 'random_forest_model.pkl')

# import joblib

# # Save model to Drive
# joblib.dump(rf_model, '/content/drive/MyDrive/random_forest_model.pkl')

# # Load the model from the file
# loaded_model = joblib.load('random_forest_model.pkl')

# # Define sleep/wake threshold based on ENMO
threshold = 0.03  # Experimentally chosen threshold for sleep detection
df2['sleep_state'] = (df2['enmo'] < threshold).astype(int)

df2.compute().info()



xxximport pandas as pd
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# ==== Step 1: Load the Test Data ====


# ==== Step 2: Select Features and Target from Test Data ====
X_test = df2[['step', 'anglez', 'enmo']]  # Must match training features
y_test = df2['sleep_state']               # True labels for evaluation

# ==== Step 3: Apply Same Scaling as Training ====
X_test_scaled = scaler.transform(X_test)          # Use same `scaler` fitted earlier

# ==== Step 4: Predict and Evaluate ====
y_pred = rf_model.predict(X_test_scaled)

# Accuracy Score
accuracy = accuracy_score(y_test, y_pred)
print("Model Accuracy:", accuracy)

# Classification Report
print("Classification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)

# Plot Confusion Matrix
plt.figure(figsize=(5, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=["Sleep", "Wake"], yticklabels=["Sleep", "Wake"])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

"""## ‚úÖ Model Evaluation Summary (Sleep vs Wake)

### üìä Overall Accuracy:
- **Accuracy**: `90.67%` (‚âà 0.9067)

---

### üìà Classification Report:

| Class  | Precision | Recall | F1-Score | Support |
|--------|-----------|--------|----------|---------|
| Sleep  | 0.75      | 1.00   | 0.86     | 126     |
| Wake   | 1.00      | 0.87   | 0.93     | 324     |
| **Macro Avg** | 0.88 | 0.94 | 0.89 | 450 |
| **Weighted Avg** | 0.93 | 0.91 | 0.91 | 450 |

---

### üßÆ Confusion Matrix:

|               | Predicted: Sleep | Predicted: Wake |
|---------------|------------------|------------------|
| **Actual: Sleep** | ‚úÖ 126             | ‚ùå 0                |
| **Actual: Wake**  | ‚ùå 42              | ‚úÖ 282              |

---

### üîç Insights:
- **Sleep (Class 0)**:
  - Perfect recall (1.00): All actual sleep cases correctly predicted.
  - Precision is lower (0.75): Some wake cases misclassified as sleep.
- **Wake (Class 1)**:
  - High precision (1.00): All predicted wake are correct.
  - Lower recall (0.87): 42 actual wake cases misclassified as sleep.

### ‚ö†Ô∏è Considerations:
- There is a **slight bias towards classifying "sleep"** due to perfect recall but lower precision for that class.
- **False negatives in wake detection (42 cases)** may be crucial depending on application (e.g., sleep monitoring in healthcare).

> üéØ Aim to further improve **wake recall** and **sleep precision** for balanced performance.

## Train_events.csv

## reading the data
### üìàSimple EDA
"""

import pandas as pd
import numpy as np

file1=("/content/drive/MyDrive/Sleep_Data/train_events.csv")# train_events

'contents/drive'

file1=pd.read_csv(file1)
df1=file1.copy()

df1.head()

df1.shape

df1.info()

df1.isnull().sum()

df1.describe()

df1['step'].isnull().sum()

df1['timestamp'].isnull().sum()

"""### üìÅ Analysis of `train_events.csv`

- The dataset contains **4,923 missing values** in both the **`step`** and **`timestamp`** columns.
- To ensure proper analysis and preprocessing, it is necessary to **convert the data types** of columns like:
  - **`series_id`** ‚Üí categorical (`astype('category')`)
  - **`timestamp`** ‚Üí datetime format (`pd.to_datetime`)

## üßπ cleaning
"""

df1.info()

# df1=pd.read_csv(file1)

# Drop rows with missing values in 'step' and 'timestamp' columns
df1 = df1.dropna(subset=['step', 'timestamp'])

"""## PreProcessing"""

# Convert data types (if needed)
df1["series_id"] = df1["series_id"].astype("category")
df1['timestamp']=pd.to_datetime(df1['timestamp'],utc=True)

if pd.api.types.is_datetime64_any_dtype(df1['timestamp']):
    df1['year'] = df1['timestamp'].dt.year
    df1['month'] = df1['timestamp'].dt.month
    df1['day'] = df1['timestamp'].dt.day
    df1['hour'] = df1['timestamp'].dt.hour
    df1['minute'] = df1['timestamp'].dt.minute
    df1['second'] = df1['timestamp'].dt.second
else:
    print("timestamp column is not datetime. Check for format or NaNs.")

# Replace 'event' column with 'onset' (1) and 'wakeup' (0)
df1['event'] = df1['event'].replace({'onset': 1, 'wakeup': 0})
df1 = df1.rename(columns={'event': 'events'})

# Display first few rows to verify
print(df1.head())

df1

df1 = df1.iloc[1:]

df1

df1.info()

"""### üîß Data Preprocessing: Handling Nulls & Data Types

- Removed rows with null values in `step` and `timestamp` columns to ensure data quality.
- Converted `series_id` to categorical for memory efficiency.
- Parsed `timestamp` column to datetime format for time-based operations.

## üìà Exploratory Data Analysis
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Univariate analysis for 'step'
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Histogram of 'step'
sns.histplot(df1['step'], bins=50, ax=axes[0], kde=True, color='skyblue')
axes[0].set_title('Distribution of Step')
axes[0].set_xlabel('Step')
axes[0].set_ylabel('Frequency')
axes[0].grid(True)


# Boxplot of 'step'
sns.boxplot(x=df1['step'], ax=axes[1], color='lightcoral')
axes[1].set_title('Boxplot of Step')
axes[1].set_xlabel('Step')
axes[1].grid(True)

plt.tight_layout()
plt.show()

"""## üìä Step Data Insights

### 1. **Distribution (Left Plot)**
- The **distribution is right-skewed**, meaning most people have **lower step counts**.
- The majority of data is concentrated **below 300,000 steps**.
- There are **fewer individuals** with step counts above **400,000**, and the number continues to decline as steps increase.

---

### 2. **Boxplot (Right Plot)**
- The **median** (middle value) of steps lies around **200,000**.
- The **interquartile range (IQR)** (middle 50% of data) spans roughly from **100,000 to 300,000 steps**.
- There are several **outliers** above **600,000 steps**, indicating unusually high activity levels for some individuals.
- The lower whisker extends close to **0**, suggesting some individuals have very low step counts.

---

## ‚úÖ Summary
- Most users fall in the **100,000‚Äì300,000 step range**.
- **High step counts** beyond **600,000** are **outliers**.
- The data is **not normally distributed**; it is **positively skewed**.

"""

# Univariate analysis for 'Night'
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Histogram + KDE Plot
sns.histplot(df1['night'], bins=100, kde=True, color='salmon', ax=axes[0])
axes[0].set_title('Distribution of night')
axes[0].set_xlabel('night')
axes[0].set_ylabel('Frequency')
axes[0].grid(True)

# Boxplot
sns.boxplot(x=df1['night'], color='lightcoral', ax=axes[1])
axes[1].set_title('Boxplot of night')
axes[1].set_xlabel('night')
axes[1].grid(True)

# Adjust layout
plt.tight_layout()
plt.show()

"""## üåô Night Data Insights

### 1. **Distribution Plot (Left Plot)**
- The distribution of "night" is **right-skewed**, with **most values below 20**.
- A **high frequency** is observed in the range of **0 to 20 nights**.
- Frequency gradually decreases as the number of nights increases.
- Very few observations have more than **30 nights**.

---

### 2. **Boxplot (Right Plot)**
- The **median** is around **12 nights**, indicating that half the values lie below this.
- The **interquartile range (IQR)** extends from approximately **5 to 20 nights**.
- There are **several outliers beyond 35 nights**, suggesting **unusually high values**.
- The box is asymmetric, with a longer right whisker, reaffirming **positive skewness**.

---

## ‚úÖ Summary
- Most people have **less than 20 nights** recorded.
- The data is **positively skewed**, with a small number of **high-value outliers**.
- Central tendency and variability suggest that **night stays are usually short**, with a few long-term cases.

"""

# Univariate analysis for 'enmo'
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Histogram with custom color
sns.histplot(df1['events'], kde=True, ax=axes[0], color='royalblue')
axes[0].set_title('Distribution of ENMO')
axes[0].set_xlabel('events')
axes[0].set_ylabel('Frequency')

# Box plot with custom color
sns.boxplot(y=df1['events'], ax=axes[1], color='orange')
axes[1].set_title('Box Plot of Event')
axes[1].set_ylabel('Frequnecy')

plt.tight_layout()
plt.show()

"""## üìä ENMO and Event Data Insights

### 1. **Distribution of ENMO (Left Plot)**
- The ENMO (Euclidean Norm Minus One) values are **bimodal and binary**:
  - **Sharp peaks at 0 and 1**, indicating **discrete values**.
  - Very **few or no values between 0.1 and 0.9**.
- This suggests ENMO is being treated like a **binary classification signal**, likely:
  - **0 = no event or low activity**
  - **1 = event or high activity**

---

### 2. **Box Plot of Event (Right Plot)**
- The boxplot shows a **solid rectangle**, meaning:
  - All values in the "event" column are the **same** (most likely all are `1`).
  - There's **no variability**, hence no box, whiskers, or outliers are visible.

---

## ‚úÖ Summary
- **ENMO** is behaving like a binary feature (possibly a thresholded signal).
- **Event** variable is **constant**, which could be an issue:
  - No variation means it's not useful for predictive modeling.
  - May need to verify the data source or check for preprocessing issues.

> üõ†Ô∏è **Next step:** Consider checking the raw data and understanding why "event" has no variability. You may want to remove or re-engineer it.

"""

# Univariate analysis for time-related features
fig, axes = plt.subplots(2, 2, figsize=(16, 8))

# Day plot
sns.countplot(x='day', data=df1, ax=axes[0, 0], palette='pastel')
axes[0, 0].set_title('Distribution of Day')
axes[0, 0].grid(True)

# Hour plot
sns.countplot(x='hour', data=df1, ax=axes[0, 1], palette='coolwarm')
axes[0, 1].set_title('Distribution of Hour')
axes[0, 1].grid(True)

# Minute plot
sns.histplot(df1['minute'], bins=60, ax=axes[1, 0], kde=False, color='skyblue')
axes[1, 0].set_title('Distribution of Minute')
axes[1, 0].grid(True)

# Second plot
sns.histplot(df1['second'], bins=60, ax=axes[1, 1], kde=False, color='lightgreen')
axes[1, 1].set_title('Distribution of Second')
axes[1, 1].grid(True)

plt.tight_layout()
plt.show()

"""## üïí Time Feature Distributions

### üìÖ Day
- Data is **evenly spread** across all 31 days, with no significant gaps or spikes.
- This suggests a **consistent daily collection** of data.

### üïê Hour
- High activity during **midnight to 4 AM** and **10 AM to 12 PM**.
- Very little activity from **4 PM to 10 PM**, with a small spike at **11 PM**.
- Indicates user/system behavior is **time-sensitive**, possibly focused on night or morning periods.

### ‚è±Ô∏è Minute
- Clear pattern of readings every **5 minutes** (e.g., 0, 5, 10, ..., 55).
- Suggests the data was collected using a **fixed interval schedule** (likely automated).

### ‚è≤Ô∏è Second
- All timestamps show **0 seconds**, meaning data is captured at the **start of each minute**.
- Confirms regular, **precise time logging** with no randomness in second values.

> üìå Overall: The data shows a **structured and periodic collection pattern**, mainly active at specific hours with consistent time intervals.

## Bi-Variet
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Create 1x2 subplot layout
fig, axes = plt.subplots(1, 2, figsize=(15, 6))  # Adjust height for better layout
plt.tight_layout(pad=5.0)

# --- Scatter Plot ---
sns.scatterplot(x='step', y='night', data=df1, hue='events', ax=axes[0])
axes[0].set_title('Scatter Plot: Step vs. Night (Colored by Event)')
axes[0].set_xlabel('Step')
axes[0].set_ylabel('Night')

# --- Boxen Plot ---
sns.boxenplot(x='events', y='step', data=df1, palette='Set2', ax=axes[1])
axes[1].set_title('Boxen Plot: Step Distribution by Event Type')
axes[1].set_xlabel('Event')
axes[1].set_ylabel('Step')

plt.show()

"""## üìä Event Distribution by Step and Night

### üîµ Scatter Plot: Step vs. Night (Colored by Event)
- The plot shows a **clear linear relationship** between `Step` and `Night` ‚Äî indicating data is **evenly spaced** across nights.
- Both `Event = 0` and `Event = 1` are **consistently spread** across all nights.
- This suggests that events (both 0 and 1) occurred **uniformly over time**, with no major gaps or bursts in event activity.

### üì¶ Boxen Plot: Step Distribution by Event Type
- The `Step` values for both event types show a **similar spread** with a **slight difference in central tendency**:
  - Median step count is **slightly higher for Event 0** compared to Event 1.
- Both distributions have a **wide interquartile range (IQR)**, indicating **high variance**.
- **Outliers** are present for both event types, especially in higher step values, but are more prominent in `Event = 1`.
- The step distribution is **slightly skewed**, possibly indicating more steps recorded in fewer sessions (or participants).

> üìå Overall:  
- Events are **evenly distributed** across nights and steps.  
- Step counts exhibit **high variability**, but both event types follow a **comparable pattern**.

"""

# Create 1x2 subplot layout
fig, axes = plt.subplots(1, 2, figsize=(15, 6))  # Adjust height for better layout
plt.tight_layout(pad=5.0)
# --- Violin Plot ---
sns.violinplot(x='events', y='night', data=df1, palette='Set3', ax=axes[0])
axes[0].set_title('Violin Plot: Night Distribution by Event Type')
axes[0].set_xlabel('Event')
axes[0].set_ylabel('Night')

# --- boxplot---
sns.boxplot(x='events', y='step', data=df1, palette='Set2', ax=axes[1])

"""## üéª Violin & Box Plot Analysis: Event-wise Distribution

### üéª Violin Plot: Night Distribution by Event Type
- Both `Event 0` and `Event 1` exhibit **nearly identical distributions** over the `Night` variable.
- The shapes are symmetric and **centered around the same median (~12‚Äì13 nights)**.
- This suggests that both event types are **evenly spread across nights**, with **no temporal bias**.
- The density indicates a **higher concentration** of events during the **early and mid-range nights** (e.g., 1‚Äì25).

### üì¶ Box Plot: Step Distribution by Event Type
- The `Step` distribution for both event types has:
  - **Similar median values** (~200,000 steps),
  - **Comparable interquartile ranges (IQR)**,
  - **High variance** and the presence of **upper-end outliers** (> 650,000 steps).
- A slightly higher spread is visible in **Event 0**, but both are largely overlapping.
- This implies that **step count is not significantly different** between the two event types.

> üìå Summary:
- **Night** and **Step** distributions are **balanced across event types**.
- No strong indication of class imbalance or feature drift in these visualizations.

"""

# Multivariate Analysis: Correlation Heatmap
# Select relevant numerical features for the heatmap
numerical_features = ['step','events', 'hour','night']  # Add or remove as needed
# Calculate the correlation matrix
correlation_matrix = df1[numerical_features].corr()

# Plot the heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Correlation Heatmap of Numerical Features')
plt.show()

"""## üî• Correlation Heatmap Insights

### üîó Key Observations:
- **Strong Negative Correlation** between:
  - `events` and `hour` (**-0.84**): Indicates that events are **less likely to occur at higher hours**, or that certain hours are more/less associated with events.
- **No Strong Correlation** among other features:
  - `step` has **almost zero correlation** with `events`, `hour`, and `night`.
  - `night` is **not significantly correlated** with any other variable (all ‚âà 0).
  - `step` and `night` show a **perfect correlation of 1.00**, which might be a **data duplication or engineering artifact** ‚Äî worth validating.

> ‚ö†Ô∏è The standout relationship here is between `events` and `hour`, suggesting time of day could be a **key predictive feature** for event detection.

### ‚úÖ Summary:
- Most features are **independent**, reducing multicollinearity concerns.
- `hour` is a **critical driver of event prediction**, deserving deeper exploration.

"""

!pip install statsmodels # Install the missing statsmodels library
import pandas as pd
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.tools.tools import add_constant

# Select numerical features only (replace with your feature list if needed)
features = df1[['step', 'events', 'hour']]

# Add a constant column for intercept
features_with_const = add_constant(features)

# Calculate VIF for each feature
vif_data = pd.DataFrame()
vif_data["Feature"] = features_with_const.columns
vif_data["VIF"] = [variance_inflation_factor(features_with_const.values, i)
                   for i in range(features_with_const.shape[1])]

print(vif_data)

# Multivariate Analysis: Correlation Heatmap
# Select relevant numerical features for the heatmap
numerical_features = ['step','night']  # Add or remove as needed
# Calculate the correlation matrix
correlation_matrix = df1[numerical_features].corr()

# Plot the heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Correlation Heatmap of Numerical Features')
plt.show()

"""## üîç Correlation Heatmap: `step` vs `night`

### üîó Key Observations:
- **Perfect Positive Correlation** between:
  - `step` and `night` = **1.00**
  
This indicates that the `night` variable is likely **derived directly from `step`** or vice versa ‚Äî possibly a **feature duplication or leakage**.

### ‚ö†Ô∏è Implications:
- Including both `step` and `night` in modeling may introduce **multicollinearity**, which can confuse models like linear regression.
- You should consider:
  - Keeping **only one** of the two variables.
  - Investigating how `night` is computed (e.g., `night = 1 if 0 <= step <= 4`?).

> ‚úÖ Always check for **feature redundancy** when correlation is **very close to 1.00** ‚Äî it can help simplify models and improve generalization.


"""

import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.model_selection import StratifiedKFold
import numpy as np

# --- Preprocessing ---
X = df1[['step', 'hour']]  # Features
y = df1['events']          # Target (binary: 0 = Wake, 1 = Sleep)

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Feature Scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# --- Logistic Regression Model ---
log_reg = LogisticRegression(random_state=42)

# --- K-Fold Cross-Validation on Training Set ---
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = cross_val_score(log_reg, X_train_scaled, y_train, cv=cv, scoring='accuracy')

print("Cross-Validation Accuracy Scores:", cv_scores)
print("Mean CV Accuracy:", np.mean(cv_scores))

# --- Final Training on Full Training Set ---
log_reg.fit(X_train_scaled, y_train)

# --- Evaluation on Holdout Test Set ---
y_pred = log_reg.predict(X_test_scaled)
print("\nHoldout Test Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

import joblib

# Save the model to a file
joblib.dump(log_reg, 'log_reg_model.pkl')

